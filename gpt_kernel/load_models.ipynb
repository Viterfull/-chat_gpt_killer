{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    return torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): Encoder(\n",
       "    (sentence_embedding): SentenceEmbedding(\n",
       "      (embedding): Embedding(152, 512)\n",
       "      (position_encoder): PositionalEncoding()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (layers): SequentialEncoder(\n",
       "      (0): EncoderLayer(\n",
       "        (attention): MultiHeadAttention(\n",
       "          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (ln): LayerNorm((512,), eps=512, elementwise_affine=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (ffn): FeedFoward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (sentence_embedding): SentenceEmbedding(\n",
       "      (embedding): Embedding(152, 512)\n",
       "      (position_encoder): PositionalEncoding()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (layers): SequentialDecoder(\n",
       "      (0): DecoderLayer(\n",
       "        (self_attention): MultiHeadAttention(\n",
       "          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (ln): LayerNorm((512,), eps=512, elementwise_affine=True)\n",
       "        )\n",
       "        (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (encoder_decoder_attention): MultiHeadCrossAttention(\n",
       "          (kv_layer): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (q_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        (ffn): FeedFoward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (layer_norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=152, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformer import Transformer\n",
    "\n",
    "START_TOKEN = '<START>'\n",
    "PADDING_TOKEN = '<PADDING>'\n",
    "END_TOKEN = '<END>'\n",
    "\n",
    "trg_vocab = sorted(list(set(' abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZабвгдеёжзийклмнопрстуфхцчшщъыьэюяАБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯ1234567890.,#!@\"$;:^|\\'-=+_—?<>')))\n",
    "src_vocab = sorted(list(set(' abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZабвгдеёжзийклмнопрстуфхцчшщъыьэюяАБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯ1234567890.,#!@\"$;:^|\\'-=+_—?<>')))\n",
    "\n",
    "trg_vocab.append(START_TOKEN)\n",
    "trg_vocab.append(END_TOKEN)\n",
    "trg_vocab.append(PADDING_TOKEN)\n",
    "\n",
    "src_vocab.append(START_TOKEN)\n",
    "src_vocab.append(END_TOKEN)\n",
    "src_vocab.append(PADDING_TOKEN)\n",
    "\n",
    "index_to_trg = {k:v for k,v in enumerate(trg_vocab)}\n",
    "trg_to_index = {v:k for k,v in enumerate(trg_vocab)}\n",
    "index_to_src = {k:v for k,v in enumerate(src_vocab)}\n",
    "src_to_index = {v:k for k,v in enumerate(src_vocab)}\n",
    "\n",
    "d_model = 512\n",
    "batch_size = 50\n",
    "ffn_hidden = 2048\n",
    "num_heads = 8\n",
    "drop_prob = 0.2\n",
    "num_layers = 1\n",
    "max_sequence_length = 200\n",
    "trg_vocab_size = len(trg_vocab)\n",
    "\n",
    "ru_eng = Transformer(d_model, \n",
    "                            ffn_hidden,\n",
    "                            num_heads, \n",
    "                            drop_prob, \n",
    "                            num_layers, \n",
    "                            max_sequence_length,\n",
    "                            trg_vocab_size,\n",
    "                            src_to_index,\n",
    "                            trg_to_index,\n",
    "                            index_to_trg,\n",
    "                            START_TOKEN, \n",
    "                            END_TOKEN, \n",
    "                            PADDING_TOKEN)\n",
    "eng_ru = Transformer(d_model, \n",
    "                            ffn_hidden,\n",
    "                            num_heads, \n",
    "                            drop_prob, \n",
    "                            num_layers, \n",
    "                            max_sequence_length,\n",
    "                            trg_vocab_size,\n",
    "                            src_to_index,\n",
    "                            trg_to_index,\n",
    "                            index_to_trg,\n",
    "                            START_TOKEN, \n",
    "                            END_TOKEN, \n",
    "                            PADDING_TOKEN)\n",
    "\n",
    "ru_eng.load_state_dict(torch.load(\"models/ru_eng_trans.pth\"))\n",
    "eng_ru.load_state_dict(torch.load(\"models/eng_ru_trans.pt\"))\n",
    "\n",
    "def get_device():\n",
    "    return torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "device = get_device()\n",
    "\n",
    "ru_eng.to(device)\n",
    "eng_ru.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- Executive Board States'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_eng.translate(\"Я люблю группу король и шут\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Проект дня'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_ru.translate(\"Good night\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
