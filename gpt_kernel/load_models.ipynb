{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformer import Transformer\n",
    "\n",
    "START_TOKEN = '<START>'\n",
    "PADDING_TOKEN = '<PADDING>'\n",
    "END_TOKEN = '<END>'\n",
    "\n",
    "trg_vocab = list(set(' abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZабвгдеёжзийклмнопрстуфхцчшщъыьэюяАБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯ1234567890.,#!@\"$;:^|\\'-=+_—?<>'))\n",
    "src_vocab = list(set(' abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZабвгдеёжзийклмнопрстуфхцчшщъыьэюяАБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯ1234567890.,#!@\"$;:^|\\'-=+_—?<>'))\n",
    "\n",
    "trg_vocab.append(START_TOKEN)\n",
    "trg_vocab.append(END_TOKEN)\n",
    "trg_vocab.append(PADDING_TOKEN)\n",
    "\n",
    "src_vocab.append(START_TOKEN)\n",
    "src_vocab.append(END_TOKEN)\n",
    "src_vocab.append(PADDING_TOKEN)\n",
    "\n",
    "index_to_trg = {k:v for k,v in enumerate(trg_vocab)}\n",
    "trg_to_index = {v:k for k,v in enumerate(trg_vocab)}\n",
    "index_to_src = {k:v for k,v in enumerate(src_vocab)}\n",
    "src_to_index = {v:k for k,v in enumerate(src_vocab)}\n",
    "\n",
    "d_model = 512\n",
    "batch_size = 50\n",
    "ffn_hidden = 2048\n",
    "num_heads = 8\n",
    "drop_prob = 0.2\n",
    "num_layers = 1\n",
    "max_sequence_length = 200\n",
    "trg_vocab_size = len(trg_vocab)\n",
    "\n",
    "ru_eng_translator = Transformer(d_model, \n",
    "                            ffn_hidden,\n",
    "                            num_heads, \n",
    "                            drop_prob, \n",
    "                            num_layers, \n",
    "                            max_sequence_length,\n",
    "                            trg_vocab_size,\n",
    "                            src_to_index,\n",
    "                            trg_to_index,\n",
    "                            index_to_trg,\n",
    "                            START_TOKEN, \n",
    "                            END_TOKEN, \n",
    "                            PADDING_TOKEN)\n",
    "\n",
    "eng_ru_translator = Transformer(d_model, \n",
    "                            ffn_hidden,\n",
    "                            num_heads, \n",
    "                            drop_prob, \n",
    "                            num_layers, \n",
    "                            max_sequence_length,\n",
    "                            trg_vocab_size,\n",
    "                            src_to_index,\n",
    "                            trg_to_index,\n",
    "                            index_to_trg,\n",
    "                            START_TOKEN, \n",
    "                            END_TOKEN, \n",
    "                            PADDING_TOKEN)\n",
    "\n",
    "ru_eng_translator.load_state_dict(torch.load('models/ru_eng_trans.pth'))\n",
    "eng_ru_translator.load_state_dict(torch.load('models/eng_ru_trans.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    return torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): Encoder(\n",
       "    (sentence_embedding): SentenceEmbedding(\n",
       "      (embedding): Embedding(152, 512)\n",
       "      (position_encoder): PositionalEncoding()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (layers): SequentialEncoder(\n",
       "      (0): EncoderLayer(\n",
       "        (attention): MultiHeadAttention(\n",
       "          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (ln): LayerNorm((512,), eps=512, elementwise_affine=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (ffn): FeedFoward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (sentence_embedding): SentenceEmbedding(\n",
       "      (embedding): Embedding(152, 512)\n",
       "      (position_encoder): PositionalEncoding()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (layers): SequentialDecoder(\n",
       "      (0): DecoderLayer(\n",
       "        (self_attention): MultiHeadAttention(\n",
       "          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (ln): LayerNorm((512,), eps=512, elementwise_affine=True)\n",
       "        )\n",
       "        (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (encoder_decoder_attention): MultiHeadCrossAttention(\n",
       "          (kv_layer): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (q_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        (ffn): FeedFoward(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (layer_norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=152, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_eng_translator.to(device)\n",
    "eng_ru_translator.to(device)\n",
    "\n",
    "ru_eng_translator.eval()\n",
    "eng_ru_translator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'g$$.XЫЭ$!.M$d6ЫgбГк$кT!Md!кл$'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_eng_translator.translate(\"Привет, как дела?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ЙR<ULТJR<ЫbVЫbНVKТLТnШR'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_ru_translator.translate(\"Hi, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "PytorchStreamReader failed locating file constants.pkl: file not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model1 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39mmodels/eng_ru_trans.pt\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m model2 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39mmodels/ru_eng_trans.pt\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/jit/_serialization.py:162\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, _extra_files, _restore_shapes)\u001b[0m\n\u001b[1;32m    160\u001b[0m cu \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39mCompilationUnit()\n\u001b[1;32m    161\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(f, (\u001b[39mstr\u001b[39m, pathlib\u001b[39m.\u001b[39mPath)):\n\u001b[0;32m--> 162\u001b[0m     cpp_module \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49mimport_ir_module(cu, \u001b[39mstr\u001b[39;49m(f), map_location, _extra_files, _restore_shapes)  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    164\u001b[0m     cpp_module \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39mimport_ir_module_from_buffer(\n\u001b[1;32m    165\u001b[0m         cu, f\u001b[39m.\u001b[39mread(), map_location, _extra_files, _restore_shapes\n\u001b[1;32m    166\u001b[0m     )  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: PytorchStreamReader failed locating file constants.pkl: file not found"
     ]
    }
   ],
   "source": [
    "model1 = torch.load(\"models/eng_ru_trans.pt\")\n",
    "model2 = torch.load(\"models/ru_eng_trans.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model1\u001b[39m.\u001b[39;49meval()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "model1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(model, src_sentence):\n",
    "        \n",
    "        model.eval()\n",
    "        max_sequence_length = model.max_sequence_length\n",
    "        device = get_device()\n",
    "        src_sentence = (src_sentence,)\n",
    "        trg_sentence = (\"\",)\n",
    "        \n",
    "        for word_counter in range(max_sequence_length):\n",
    "\n",
    "            encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask=create_masks(src_sentence, trg_sentence)\n",
    "            predictions = model(src_sentence,\n",
    "                                    trg_sentence,\n",
    "                                    encoder_self_attention_mask.to(device), \n",
    "                                    decoder_self_attention_mask.to(device), \n",
    "                                    decoder_cross_attention_mask.to(device),\n",
    "                                    enc_start_token=False,\n",
    "                                    enc_end_token=False,\n",
    "                                    dec_start_token=True,\n",
    "                                    dec_end_token=False)\n",
    "            \n",
    "            next_token_prob_distribution = predictions[0][word_counter]\n",
    "            next_token_index = torch.argmax(next_token_prob_distribution).item()\n",
    "            next_token = model.index_to_trg[next_token_index]\n",
    "            \n",
    "            if next_token == model.END_TOKEN:\n",
    "                break\n",
    "\n",
    "            trg_sentence = (trg_sentence[0] + next_token, )\n",
    "        return trg_sentence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m translate(model1, \u001b[39m\"\u001b[39;49m\u001b[39mwad\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[17], line 3\u001b[0m, in \u001b[0;36mtranslate\u001b[0;34m(model, src_sentence)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtranslate\u001b[39m(model, src_sentence):\n\u001b[0;32m----> 3\u001b[0m         model\u001b[39m.\u001b[39;49meval()\n\u001b[1;32m      4\u001b[0m         max_sequence_length \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mmax_sequence_length\n\u001b[1;32m      5\u001b[0m         device \u001b[39m=\u001b[39m get_device()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "translate(model1, \"wad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
